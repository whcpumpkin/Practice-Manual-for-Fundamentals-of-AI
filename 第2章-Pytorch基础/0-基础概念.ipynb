{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. å¼ é‡ï¼ˆTensorï¼‰**\n",
    "- **å®šä¹‰**ï¼šPyTorchä¸­çš„åŸºæœ¬æ•°æ®ç»“æ„ï¼Œæ˜¯å¤šç»´æ•°ç»„çš„æ‰©å±•ï¼Œæ”¯æŒGPUåŠ é€Ÿè®¡ç®—å’Œè‡ªåŠ¨å¾®åˆ†ã€‚\n",
    "- **å…³é”®ç‚¹**ï¼š\n",
    "  - ç±»ä¼¼NumPyçš„`ndarray`ï¼Œä½†å¯é€šè¿‡`.to(device)`è¿ç§»åˆ°GPUæˆ–è€…å…¶å®ƒåŠ é€Ÿå¡ï¼ˆæ˜‡è…¾ã€å¯’æ­¦çºªMLUï¼‰ã€‚\n",
    "  - åˆ›å»ºæ–¹å¼ï¼š`torch.tensor(data)`, `torch.zeros()`, `torch.rand()`ç­‰ã€‚æˆ–è€…ä»`List`å’Œ`np.arrary`è½¬æ¢ï¼Œ`torch.tensor(data_list)`æˆ–`torch.from_numpy(data_np)`ã€‚\n",
    "  - æ”¯æŒæ•°å­¦è¿ç®—ï¼ˆå¦‚åŠ å‡ä¹˜é™¤ã€çŸ©é˜µä¹˜æ³•`@`æˆ–`torch.matmul()`ï¼‰ã€‚\n",
    "  - å½¢çŠ¶æ“ä½œï¼š`view()`ï¼ˆéœ€è¿ç»­å†…å­˜ï¼‰ã€`reshape()`ï¼ˆè‡ªåŠ¨å¤„ç†éè¿ç»­å†…å­˜ï¼‰ã€‚\n",
    "  - ç±»å‹è½¬æ¢ï¼š`float()`ã€`long()`ã€`int()`ã€`bool()`ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x å½¢çŠ¶: torch.Size([2, 2])\n",
      "x æ•°æ®ç±»å‹: torch.float32\n",
      "y å½¢çŠ¶: torch.Size([1, 4])\n",
      "z æ•°æ®ç±»å‹: torch.int32\n",
      "w è®¾å¤‡: cuda:0\n",
      "x2 å½¢çŠ¶: torch.Size([4])\n",
      "x3 å½¢çŠ¶: torch.Size([2, 2])\n",
      "x4 å½¢çŠ¶: torch.Size([2, 2])\n",
      "x5 å½¢çŠ¶: torch.Size([1, 4])\n",
      "x6 å½¢çŠ¶: torch.Size([4])\n",
      "x7 å½¢çŠ¶: torch.Size([4, 2])\n",
      "x7 å…ƒç´ : tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [1., 2.],\n",
      "        [3., 4.]], grad_fn=<CatBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# åˆ›å»ºä¸€ä¸ªå½¢çŠ¶ä¸º(2, 2)çš„å¼ é‡ï¼Œæ•°æ®ç±»å‹ä¸ºfloat32ï¼Œå¯æ±‚å¯¼ã€‚\n",
    "x = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32, requires_grad=True,device=\"cpu\")\n",
    "print(\"x å½¢çŠ¶:\", x.shape)\n",
    "print(\"x æ•°æ®ç±»å‹:\", x.dtype)\n",
    "y = x.view(1, 4)\n",
    "print(\"y å½¢çŠ¶:\", y.shape)\n",
    "z = x.int()\n",
    "print(\"z æ•°æ®ç±»å‹:\", z.dtype)\n",
    "w = x.to(\"cuda\")\n",
    "print(\"w è®¾å¤‡:\", w.device)\n",
    "x2 = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
    "x3 = x2.reshape(2, 2)\n",
    "print(\"x2 å½¢çŠ¶:\", x2.shape)\n",
    "print(\"x3 å½¢çŠ¶:\", x3.shape)\n",
    "x4 = x3.transpose(0, 1)\n",
    "print(\"x4 å½¢çŠ¶:\", x4.shape)\n",
    "x5 = x2.unsqueeze(0)\n",
    "print(\"x5 å½¢çŠ¶:\", x5.shape)\n",
    "x6 = x2.squeeze(0)\n",
    "print(\"x6 å½¢çŠ¶:\", x6.shape)\n",
    "x7 = torch.cat([x, x3], dim=0)\n",
    "print(\"x7 å½¢çŠ¶:\", x7.shape)\n",
    "print(\"x7 å…ƒç´ :\", x7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. è‡ªåŠ¨å¾®åˆ†ï¼ˆAutogradï¼‰**\n",
    "- **å®šä¹‰**ï¼šPyTorché€šè¿‡`autograd`æ¨¡å—è‡ªåŠ¨è®¡ç®—æ¢¯åº¦ï¼Œç”¨äºåå‘ä¼ æ’­ã€‚\n",
    "- **å…³é”®ç‚¹**ï¼š\n",
    "  - `requires_grad=True`ï¼šæ ‡è®°éœ€è¦è®¡ç®—æ¢¯åº¦çš„å¼ é‡ã€‚\n",
    "  - `backward()`ï¼šä»æ ‡é‡å¼ é‡è§¦å‘æ¢¯åº¦è®¡ç®—ï¼Œç»“æœå­˜å‚¨åœ¨`.grad`å±æ€§ä¸­ã€‚\n",
    "  - è®¡ç®—å›¾ï¼šåŠ¨æ€æ„å»ºï¼Œæ¯æ¬¡å‰å‘ä¼ æ’­ç”Ÿæˆæ–°å›¾ã€‚\n",
    "  - ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼š`torch.no_grad()`ç¦ç”¨æ¢¯åº¦è·Ÿè¸ªï¼ˆå¦‚æ¨ç†æ—¶ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2])\n",
      "tensor([3., 8.], grad_fn=<MulBackward0>)\n",
      "x.grad: tensor([3., 4.])\n",
      "y.grad: tensor([1., 2.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1., 2.], requires_grad=True)\n",
    "y = torch.tensor([3., 4.], requires_grad=True)\n",
    "z = x * y\n",
    "print(z.shape)\n",
    "print(z)\n",
    "z.sum().backward() #è®¡ç®—æ¢¯åº¦\n",
    "print(\"x.grad:\", x.grad) #è¾“å‡ºæ¢¯åº¦å€¼\n",
    "print(\"y.grad:\", y.grad) #è¾“å‡ºæ¢¯åº¦å€¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åœ¨ä¸‹æ–¹çš„ä»£ç å½“ä¸­ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªç®€å•çš„ç¥ç»ç½‘ç»œã€‚\n",
    "å¹¶ä½¿ç”¨ **å‡æ–¹è¯¯å·®ï¼ˆMSELossï¼‰** è®¡ç®—æŸå¤±ã€‚æˆ‘ä»¬å¯ä»¥ç”¨ **LaTeX** è¯­è¨€æ¥è¡¨ç¤ºå‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­ï¼ˆæ¢¯åº¦è®¡ç®—ï¼‰çš„å…¬å¼ã€‚  \n",
    "\n",
    "---\n",
    "\n",
    "### **1. å‰å‘ä¼ æ’­**\n",
    "è®¾ï¼š\n",
    "- **è¾“å…¥** $ x \\in \\mathbb{R}^{bs\\times 3} $ï¼Œå…¶ä¸­ $ bs $ æ˜¯æ‰¹é‡å¤§å°\n",
    "- **ç¬¬ä¸€å±‚æƒé‡** $ W_1 \\in \\mathbb{R}^{5 \\times 3} $, **ç¬¬ä¸€å±‚åç½®** $ b_1 \\in \\mathbb{R}^5 $\n",
    "- **ç¬¬äºŒå±‚æƒé‡** $ W_2 \\in \\mathbb{R}^{1 \\times 5} $, **ç¬¬äºŒå±‚åç½®** $ b_2 \\in \\mathbb{R}^1 $\n",
    "- **ReLU æ¿€æ´»å‡½æ•°** $ \\sigma(x) = \\max(0, x) $\n",
    "\n",
    "åˆ™ï¼š\n",
    "\n",
    "$h_1 = W_1 x + b_1 \\\\$\n",
    "$a_1 = \\sigma(h_1) = \\max(0, h_1)\\\\$\n",
    "$h_2 = W_2 a_1 + b_2\\\\$\n",
    "$y_{\\text{pred}} = h_2\\\\$\n",
    "\n",
    "### **2. æŸå¤±å‡½æ•°**\n",
    "æŸå¤±ä½¿ç”¨ **å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰**ï¼š\n",
    "$\\mathcal{L} = (y_{\\text{pred}} - y_{\\text{true}})^2\\\\$\n",
    "\n",
    "---\n",
    "\n",
    "### **3. åå‘ä¼ æ’­**\n",
    "#### **è®¡ç®—æ¢¯åº¦**\n",
    "1. **æŸå¤±å¯¹æœ€ç»ˆè¾“å‡º** $ h_2 $ çš„å¯¼æ•°ï¼š\n",
    "   $\\\\\\frac{\\partial \\mathcal{L}}{\\partial h_2} = 2 (h_2 - y_{\\text{true}})\\\\$\n",
    "\n",
    "2. **å¯¹ç¬¬äºŒå±‚æƒé‡ $ W_2 $ å’Œåç½® $ b_2 $ è®¡ç®—æ¢¯åº¦**ï¼š\n",
    "   $\\\\\n",
    "   \\frac{\\partial \\mathcal{L}}{\\partial W_2} = \\frac{\\partial \\mathcal{L}}{\\partial h_2} \\cdot \\frac{\\partial h_2}{\\partial W_2}\n",
    "   = 2 (h_2 - y_{\\text{true}}) \\cdot a_1^T\n",
    "   \\\\$\n",
    "   $\n",
    "   \\frac{\\partial \\mathcal{L}}{\\partial b_2} = \\frac{\\partial \\mathcal{L}}{\\partial h_2} \\cdot \\frac{\\partial h_2}{\\partial b_2}\n",
    "   = 2 (h_2 - y_{\\text{true}})\n",
    "   $\n",
    "\n",
    "3. **å¯¹ç¬¬ä¸€å±‚æ¿€æ´» $ a_1 $ è®¡ç®—æ¢¯åº¦**ï¼š\n",
    "   $\n",
    "\\\\\n",
    "   \\frac{\\partial \\mathcal{L}}{\\partial a_1} = \\frac{\\partial \\mathcal{L}}{\\partial h_2} \\cdot W_2\n",
    "   = 2 (h_2 - y_{\\text{true}}) W_2\n",
    "   $\n",
    "\n",
    "4. **å¯¹ç¬¬ä¸€å±‚çš„è¾“å…¥ $ h_1 $ è®¡ç®—æ¢¯åº¦ï¼ˆè€ƒè™‘ ReLUï¼‰**ï¼š\n",
    "   $\n",
    "   \\\\\n",
    "   \\frac{\\partial \\mathcal{L}}{\\partial h_1} = \\frac{\\partial \\mathcal{L}}{\\partial a_1} \\odot \\sigma'(h_1)\\\\$\n",
    "   å…¶ä¸­\n",
    "   $\n",
    "   \\sigma'(h_1) =\n",
    "   \\begin{cases}\n",
    "   1, & h_1 > 0 \\\\\n",
    "   0, & h_1 \\leq 0\n",
    "   \\end{cases}\n",
    "   \\\\$\n",
    "   å› æ­¤ï¼š\n",
    "   $\n",
    "   \\frac{\\partial \\mathcal{L}}{\\partial h_1} = \\left(2 (h_2 - y_{\\text{true}}) W_2\\right) \\odot \\mathbb{1}(h_1 > 0)\n",
    "   $\n",
    "\n",
    "5. **å¯¹ç¬¬ä¸€å±‚æƒé‡ $ W_1 $ å’Œåç½® $ b_1 $ è®¡ç®—æ¢¯åº¦**ï¼š\n",
    "   $\\\\\n",
    "   \\frac{\\partial \\mathcal{L}}{\\partial W_1} = \\frac{\\partial \\mathcal{L}}{\\partial h_1} \\cdot x\n",
    "   \\\\$\n",
    "   $\n",
    "   \\frac{\\partial \\mathcal{L}}{\\partial b_1} = \\frac{\\partial \\mathcal{L}}{\\partial h_1}\n",
    "   $\n",
    "\n",
    "---\n",
    "\n",
    "### **æœ€ç»ˆæ¢¯åº¦æ›´æ–°**\n",
    "åœ¨åå‘ä¼ æ’­è¿‡ç¨‹ä¸­ï¼ŒPyTorch ä¼šè‡ªåŠ¨è®¡ç®—è¿™äº›æ¢¯åº¦ï¼Œå¹¶ç”¨äº **æ¢¯åº¦ä¸‹é™ä¼˜åŒ–**ï¼š\n",
    "$\n",
    "W_i = W_i - \\eta \\frac{\\partial \\mathcal{L}}{\\partial W_i}\n",
    "$\n",
    "$\n",
    "b_i = b_i - \\eta \\frac{\\partial \\mathcal{L}}{\\partial b_i}\n",
    "$\n",
    "å…¶ä¸­ $ \\eta $ æ˜¯å­¦ä¹ ç‡ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "è¿™æ ·ï¼Œä½ çš„ç¥ç»ç½‘ç»œå°±å®Œæˆäº†ä¸€æ¬¡å‰å‘ä¼ æ’­ã€æŸå¤±è®¡ç®—å’Œåå‘ä¼ æ’­çš„å®Œæ•´æ•°å­¦è¿‡ç¨‹ã€‚ğŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3])\n",
      "h1: tensor([[-0.7639,  0.5218,  1.3314, -0.7480,  0.2545]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "a1: tensor([[0.0000, 0.5218, 1.3314, 0.0000, 0.2545]], grad_fn=<ReluBackward0>)\n",
      "h2: tensor([[-0.5780]], grad_fn=<AddmmBackward0>)\n",
      "y_true: tensor([[1.]])\n",
      "y_pred: tensor([[-0.5780]], grad_fn=<AddmmBackward0>)\n",
      "loss: tensor(2.4900, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "\n",
      "------Gradient of Layer_2------\n",
      "Auto Layer_2.weight.grad: tensor([[ 0.0000, -1.6468, -4.2019,  0.0000, -0.8033]])\n",
      "Manual Layer_2.weight.grad: tensor([[-0.0000],\n",
      "        [-1.6468],\n",
      "        [-4.2019],\n",
      "        [-0.0000],\n",
      "        [-0.8033]], grad_fn=<MulBackward0>)\n",
      "Auto Layer_2.bias.grad: tensor([-3.1559])\n",
      "Manual Layer_2.bias.grad: tensor([[-3.1559]], grad_fn=<MulBackward0>)\n",
      "\n",
      "\n",
      "------Gradient of Layer_1------\n",
      "First Row of Auto Layer_1.weight.grad: tensor([-0.1434, -1.4336,  0.5011])\n",
      "First Row of Manual Layer_1.weight.grad: tensor([-0.1434, -1.4336,  0.5011], grad_fn=<SliceBackward0>)\n",
      "Auto Layer_1.bias.grad: tensor([ 0.0000, -0.8949,  0.7276,  0.0000,  0.7865])\n",
      "Manual Layer_1.bias.grad: tensor([ 0.0000, -0.8949,  0.7276,  0.0000,  0.7865], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "Layer_1 = torch.nn.Linear(3, 5)\n",
    "Relu = torch.nn.ReLU()\n",
    "Layer_2 = torch.nn.Linear(5, 1)\n",
    "Loss_func = torch.nn.MSELoss()\n",
    "\n",
    "# å®šä¹‰è¾“å…¥\n",
    "x = torch.randn((1,3))\n",
    "print(x.shape)\n",
    "h1 = Layer_1(x)\n",
    "print(\"h1:\", h1)\n",
    "a1 = Relu(h1)\n",
    "print(\"a1:\", a1)\n",
    "h2 = Layer_2(a1)\n",
    "print(\"h2:\", h2)\n",
    "\n",
    "# å®šä¹‰è¾“å‡º\n",
    "y_true = torch.tensor([[1]], dtype=torch.float32)\n",
    "print(\"y_true:\", y_true)\n",
    "y_pred = h2\n",
    "print(\"y_pred:\", y_pred)\n",
    "\n",
    "# è®¡ç®—æŸå¤±\n",
    "loss = Loss_func(y_pred, y_true)\n",
    "print(\"loss:\", loss)\n",
    "# åå‘ä¼ æ’­\n",
    "loss.backward()\n",
    "print()\n",
    "print()\n",
    "print(\"------Gradient of Layer_2------\")\n",
    "\n",
    "\n",
    "print(\"Auto Layer_2.weight.grad:\", Layer_2.weight.grad)\n",
    "print(\"Manual Layer_2.weight.grad:\", 2 * (y_pred - y_true) * a1.t())\n",
    "print(\"Auto Layer_2.bias.grad:\", Layer_2.bias.grad)\n",
    "print(\"Manual Layer_2.bias.grad:\", 2 * (y_pred - y_true))\n",
    "\n",
    "print()\n",
    "print()\n",
    "print(\"------Gradient of Layer_1------\")\n",
    "\n",
    "h1_grad = 2 * (y_pred - y_true) * Layer_2.weight *h1.gt(0)\n",
    "print(\"First Row of Auto Layer_1.weight.grad:\", Layer_1.weight.grad[1,:])\n",
    "print(\"First Row of Manual Layer_1.weight.grad:\", (h1_grad.t()*x)[1,:])\n",
    "print(\"Auto Layer_1.bias.grad:\", Layer_1.bias.grad)\n",
    "print(\"Manual Layer_1.bias.grad:\", h1_grad.sum(0))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aibasis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
