# 环境变量的基本概念

**环境变量（Environment Variables）** 是操作系统或应用程序在运行时使用的动态键值对，用于存储系统或程序的配置信息。它们可以影响进程的行为，例如指定路径、控制调试模式、配置资源使用等。环境变量具有以下特点：
1. **全局性**：可被操作系统或所有运行中的进程访问。
2. **动态性**：无需修改代码即可调整程序行为。
3. **安全性**：避免将敏感信息（如密码、API密钥）硬编码到代码中。

如何查看环境变量：
- **Linux/macOS**：  
  ```bash
  printenv  # 打印所有环境变量
  echo $ENV_VAR  # 打印指定环境变量的值
  ```
- **Windows（CMD/PowerShell）**：  
  ```cmd
  set  # 打印所有环境变量
  echo %ENV_VAR%  # 打印指定环境变量的值

# 深度学习中的常见环境变量

在深度学习领域，环境变量常用于配置框架行为、优化硬件资源使用（如GPU）或调试。以下是一些关键环境变量及其作用：
（以下是Ubuntu系统中的设置方式，Windows中需要将 `export` 改为 `set`）
## 1. **GPU 相关配置**
- **`CUDA_VISIBLE_DEVICES`**  
  - **作用**：指定可见的GPU设备，控制程序使用哪些GPU。  
  - **示例**：  
    ```bash
    export CUDA_VISIBLE_DEVICES=0,1  # 仅使用第0、1号GPU
    ```

- **`TF_FORCE_GPU_ALLOW_GROWTH`**（TensorFlow专用）  
  - **作用**：防止TensorFlow占用全部GPU显存，动态分配显存。  
  - **示例**：  
    ```bash
    export TF_FORCE_GPU_ALLOW_GROWTH=true
    ```

## 2. **性能优化**
- **`OMP_NUM_THREADS`**  
  - **作用**：控制CPU并行线程数（如PyTorch的CPU计算）。  
  - **示例**：  
    ```bash
    export OMP_NUM_THREADS=4  # 限制为4线程
    ```

- **`TF_NUM_INTEROP_THREADS` / `TF_NUM_INTRAOP_THREADS`**（TensorFlow专用）  
  - **作用**：分别控制TensorFlow的并行操作（如数据预处理）和单个操作的线程数。  
  - **示例**：  
    ```bash
    export TF_NUM_INTEROP_THREADS=2
    export TF_NUM_INTRAOP_THREADS=4
    ```

## 3. **日志与调试**
- **`TF_CPP_MIN_LOG_LEVEL`**（TensorFlow专用）  
  - **作用**：控制TensorFlow日志级别，减少输出噪音。  
  - **值说明**：  
    - `0`（默认）：显示所有日志  
    - `1`：隐藏INFO日志  
    - `2`：隐藏WARNING日志  
    - `3`：隐藏ERROR日志  
  - **示例**：  
    ```bash
    export TF_CPP_MIN_LOG_LEVEL=2  # 仅显示ERROR
    ```

- **`PYTORCH_CUDA_ALLOC_CONF`**（PyTorch专用）  
  - **作用**：调试GPU显存碎片问题。  
  - **示例**：  
    ```bash
    export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128
    ```

## 4. **框架特定配置**
- **`KERAS_BACKEND`**  
  - **作用**：指定Keras的后端框架（如TensorFlow、PyTorch）。  
  - **示例**：  
    ```bash
    export KERAS_BACKEND="jax"  # 使用JAX作为后端
    ```

- **`HF_HOME`**（HuggingFace库）  
  - **作用**：指定HuggingFace模型缓存目录。  
  - **示例**：  
    ```bash
    export HF_HOME=/path/to/custom/cache
    ```

## 5. **分布式训练**
- **`MASTER_ADDR` / `MASTER_PORT`**（PyTorch分布式训练）  
  - **作用**：指定主节点IP和端口。  
  - **示例**：  
    ```bash
    export MASTER_ADDR=192.168.1.100
    export MASTER_PORT=29500
    ```

---

# 如何设置环境变量？

## 1. **临时设置（当前终端会话有效）**
- **Linux/macOS**：  
  ```bash
  export CUDA_VISIBLE_DEVICES=0
  ```
- **Windows（CMD/PowerShell）**：  
  ```cmd
  set CUDA_VISIBLE_DEVICES=0
  ```

## 2. **永久设置**
- **Linux/macOS**：  
  在 `~/.bashrc`、`~/.zshrc` 或 `~/.profile` 中添加：  
  ```bash
  export CUDA_VISIBLE_DEVICES=0
  ```
  执行 `source ~/.bashrc` 生效。

- **Windows**：  
  通过系统属性 → 高级 → 环境变量 → 添加用户/系统变量。

## 3. **Python代码中动态设置**
```python
import os
os.environ["CUDA_VISIBLE_DEVICES"] = "0"  # 仅在当前进程生效
```

## 4. **通过工具管理**
- 使用 `conda` 创建虚拟环境时设置：  
  ```bash
  conda env config vars set CUDA_VISIBLE_DEVICES=0
  ```
- 使用 `.env` 文件（配合 `python-dotenv` 库）：  
  ```python
  from dotenv import load_dotenv
  load_dotenv()  # 加载.env文件中的环境变量
  ```

---

# 总结
环境变量是深度学习开发中灵活配置资源、调试和优化性能的重要工具。合理使用它们可以避免代码硬编码问题，提升跨平台兼容性。建议通过脚本或配置文件统一管理环境变量，确保实验的可复现性。